{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITA_weather project web scraping\n",
    "\n",
    "### Goal of this part is to download  monthly data-tables of daily weather data of certain Italian cities (eg. see https://www.ilmeteo.it/portale/archivio-meteo/Roma/2019/Agosto). These will be turned into panda dataframes and exported as csv-files. \n",
    "### Specifically, we want to find all monthly tables in the period 1985-2019 (included) for every city which has available all of the monthly tables during this period. Eg. if a city x is missing the table for July 2005 it will be excluded altogether. In the end we will obtain 21,840 tables from 52 cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as Bsoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "## ITA_weather_link_finder object construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we define a new class - ITA_weather_link_finder - which will find links to webpages with the tables. First, it will find links to all such tables on the  ilmeteo.it web-portal. Then it will filter away cities for which there are missing tables during the period. It will also divide links into a given number of groups - for a bigger convenience of later scraping.\n",
    "\n",
    "## The class offers great flexibility. First, we can input start and end year of the period we want to scrape. We also input number of partitions into which we want to divide the final links. The default values are the ones we use for our project - 1985, 2019 and 2, respectively.\n",
    "## Next, the method \"region_pages\" provides regions' names (\"region_names\" attribute) and links from the initial \"https://www.ilmeteo.it/portale/archivio-meteo/\" page to the webpages of Italian regions (\"reg_links\" attribute, which is also the output of the method). \n",
    "## Method \"city_pages\" uses regional webpages to find list of cities (\"cities\" attribute) of all regions and links to the cities' data webpages (\"cities_links\" attribute, which is also the output of the method). User can limit the search to specifically chosen regions by manipulating \"reg_links\" attribute obtained by the \"region_pages\" method.\n",
    "## Method \"monthly_pages\" requires a list of cities as the input, which is saved as \"cities_subset\" attribute. This way the search for the tables can be limited to a chosen set of cities. Inputing \"cities\" attribute will result in the search for all of the cities obtained by the previous method. The links corresponding to the chosen citites are then used to obtain links to the pages with the final data-tables (\"month_links\" attribute, which is also the output of the method). Given that all cities from all of the regions are inputed, the resulting \"month_links\" attribute gives, to the best of our knowledge,  links to all of the monthly data-tables available on the web-portal from the period given by the start and end years. User is therefore not limited to use only links later filtered in the way we have chosen. \"monthly_pages\" method also provides attributes \"years_per_city\", which shows for what years there is at least 1 table available for the corresponding city in the inputed list of cities, and \"months_per_city\", which is a list of libraries in which to each year from the previous attribute months with table available  are listed. \n",
    "## Method \"filtering_cities\" returns attribute \"filtered_cities\", which is a list of those cities in \"cities_subset\" attribute (ie. cities chosen as the input of the \"monthly_pages\" method) that have tables available for all months in the researched period.\n",
    "## Method \"partitioning\" returns \"partitioned_links\", which are links to data-tables for filtered cities divided into the given number of partitions (p). It is list of p-elements, each element is list of links.\n",
    "## Finally, method \"partitioned_date_city\" construct attributes \"partitioned_cities\", \"partitioned_years\" and \"partitioned_months\", which are lists of lists of cities, years and months corresponding to each link in \"partitioned_links\" attribute. It also orders link alphabetically by cities, then by years and months from the oldest to the most recent ones.\n",
    " \n",
    "### Creation of an object of ITA_weather_link_finder class requires importation of \"requests\" and \"BeautifulSoup\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ITA_weather_link_finder:\n",
    "    \n",
    "    '''  This weather link finder searches ilmeteo.it website. It creates links to monthly tables with daily weather data in\n",
    "         Italian cities. It filters through only cities for which data for each month in the chosen interval \n",
    "         are available at the website.  \n",
    "         \n",
    "         ITA_weather_link_finder class requires importation of requests and BeautifulSoup. '''\n",
    "    def __init__(self, start_year=1985, end_year=2019, partitions=2):\n",
    "        \n",
    "        ''' At the initialization of the object we can choose the start and end years. Links to data from January to December \n",
    "        of each year between the start and end year (included) will be then found. The default values which we\n",
    "        use in our project are 1985 and 2019, respectively.\n",
    "        \n",
    "        In addition, option \"partitions\" decides into how many parts are the final links partitioned (with respect\n",
    "        to the chosen cities). This will enable user to download data by parts in order to be more time efficient \n",
    "        or if they are satisfied with only incomplete data.   '''\n",
    "            \n",
    "        self.start_year=start_year\n",
    "        self.end_year=end_year\n",
    "        self.partitions=partitions\n",
    "        self.basic_link=\"https://www.ilmeteo.it/portale/\"\n",
    "        \n",
    "        a=self.start_year\n",
    "        chosen_years=[a]\n",
    "        while a<self.end_year:                # getting the list of chosen years\n",
    "            chosen_years.append(a+1)\n",
    "            a+=1 \n",
    "        self.chosen_years=chosen_years\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Italian weather data link finder for interval {self.start_year} - {self.end_year}.\"\n",
    "       \n",
    "    \n",
    "    def region_pages(self):\n",
    "        '''   This method finds links to the pages of the regions and their names.    '''\n",
    "        self.link2=\"https://www.ilmeteo.it/portale/archivio-meteo/\"\n",
    "        beginning = requests.get(self.link2) \n",
    "        soup_beginning=Bsoup(beginning.text)\n",
    "        horalka=soup_beginning.findAll(\"td\")\n",
    "        rumba=horalka[1].findAll(\"a\")\n",
    "        reg_partial_links=[x.get(\"href\") for x in rumba]\n",
    "        self.reg_links=[self.basic_link+region for region in reg_partial_links]   # complete links\n",
    "        region_names=[x.text for x in rumba]                       # list of all regions\n",
    "        self.region_names=region_names\n",
    "        return self.reg_links\n",
    "    \n",
    "    def city_pages(self):\n",
    "        '''  This method finds links to the data pages for the cities and their names.\n",
    "        List of the regions to which search should be limited can be modified by changing \"reg_links\" attribute.\n",
    "        '''\n",
    "        cities=[]\n",
    "        cities_partial_links=[]\n",
    "        for reg_link in self.reg_links:\n",
    "            reg_page = requests.get(reg_link)\n",
    "            soup_reg_page=Bsoup(reg_page.text)\n",
    "            tea=soup_reg_page.findAll(\"div\",{\"class\":\"block noborder\"})\n",
    "            cofee=tea[0].findAll(\"a\",{\"target\":\"\"})\n",
    "            for x in cofee:\n",
    "                cities_partial_links.append(x.get(\"href\"))   # links\n",
    "                cities.append(x.text)                  # city names\n",
    "        self.cities=sorted(list(set(cities)))    # to get rid of the reccurent cities, setting alphabetical order\n",
    "        cities_partial_links=sorted(list(set(cities_partial_links)))   # to get rid of the reccurent cities, setting alphabetical order\n",
    "        self.cities_links=[self.basic_link+city_link for city_link in cities_partial_links]\n",
    "        return self.cities_links\n",
    "    \n",
    "    def monthly_pages(self, cities_list):\n",
    "        '''  This method gets links to the monthly data from the pages of the cities. It requires a list of cities\n",
    "        as input. It enables user to choose only particular cities for link searching. Inputing original \"cities\" attribute \n",
    "        as cities_list will make use of all of the cities available on the website (respectively limited to the regions \n",
    "        chosen in the previous step).  '''\n",
    "        self.cities_subset=cities_list\n",
    "        if cities_list==self.cities:\n",
    "            chosen_cities_links=self.cities_links\n",
    "        else:\n",
    "            indeces=[self.cities.index(x) for x in cities_list]\n",
    "            chosen_cities_links=[self.cities_links[x] for x in indeces]\n",
    "        city_years=[]\n",
    "        city_months=[]\n",
    "        MONTH_links=[]\n",
    "        for city in chosen_cities_links:\n",
    "            YEARS=[]\n",
    "            MONTHS=[]\n",
    "            page = requests.get(city)\n",
    "            soup1= Bsoup(page.text)\n",
    "            temps_dark = soup1.findAll(\"tr\",{'class':'dark'})  # links are inside a table with altering dark and light rows\n",
    "            temps_light = soup1.findAll(\"tr\",{'class':'light'})\n",
    "            for x in temps_dark:\n",
    "                tds=x.findAll(\"td\")\n",
    "                YEARS.append(tds[0].text)    # finds the year on the line\n",
    "                links=[y.get(\"href\") for y in tds[1].findAll(\"a\")]   # gets links to all months on the line\n",
    "                months=[y.text for y in tds[1].findAll(\"a\")]    # gets name of all months on the line\n",
    "                MONTH_links.append(links)  \n",
    "                MONTHS.append({tds[0].text:months})      # building up the library of years:corresponding_months\n",
    "            for x in temps_light:                   # repeat the previous for the light rows\n",
    "                tds=x.findAll(\"td\")\n",
    "                YEARS.append(tds[0].text)\n",
    "                links=[y.get(\"href\") for y in tds[1].findAll(\"a\")]\n",
    "                months=[y.text for y in tds[1].findAll(\"a\")]\n",
    "                MONTH_links.append(links)\n",
    "                MONTHS.append({tds[0].text:months})\n",
    "            city_years.append(sorted(YEARS))    # list of lists of years for each city during which at least some data were recorded\n",
    "            city_months.append([y for x,y in sorted([(list(x.keys()),x) for x in MONTHS])])  # list of months from which data are available\n",
    "        self.years_per_city=city_years  # for each city, what years are available\n",
    "        self.months_per_city=city_months  # for each city, library of available months corresponding to a year\n",
    "        \n",
    "        ###     Making working links to the available monthly data-tables   \n",
    "        final_links=[]\n",
    "        for city in MONTH_links:\n",
    "            for monthly_link in city:\n",
    "                final_links.append(self.basic_link+monthly_link)\n",
    "        self.month_links=final_links \n",
    "        self.MONTH_links=MONTH_links\n",
    "        return self.month_links\n",
    "    \n",
    "    def  filtering_cities(self):\n",
    "        ''' This method filters away cities for which there are some missing monthly tables during the required period. '''\n",
    "        cities=self.cities_subset\n",
    "        good_cities=[]\n",
    "        good_months=[]\n",
    "        good_years=[]\n",
    "        for i in range(len(cities)):\n",
    "            if len(self.years_per_city[i])!=0:\n",
    "                good_cities.append(cities[i])\n",
    "                good_months.append(self.months_per_city[i])\n",
    "                good_years.append(self.years_per_city[i])\n",
    "        chosen_years=self.chosen_years\n",
    "        chosen_cities=[]\n",
    "        for city in good_cities:          # getting the list of cities for which all months in the chosen years are provided\n",
    "            adidas=[]\n",
    "            for year in chosen_years:\n",
    "                string=city+\"/\"+str(year)+\"/\"+\"Gennaio\"\n",
    "                indeces=[self.MONTH_links.index(y) for y in self.MONTH_links for x in y if string in x] #is link for the January of the chosen\n",
    "                if len(indeces)!=0:                                                              # year in the list?\n",
    "                    index=indeces[0]\n",
    "                    if len(self.MONTH_links[index])==12:\n",
    "                        adidas.append(1)\n",
    "            if sum(adidas)==len(chosen_years):\n",
    "                chosen_cities.append(city)\n",
    "        self.filtered_cities=chosen_cities    # cities for which all required tables are available\n",
    "        return self.filtered_cities\n",
    "    def partitioning(self): \n",
    "        '''  Here we divide filtered cities into groups as decided by the stated number of partitions \n",
    "                 and create the final, partitioned links which we will finally use for scraping.\n",
    "                 Along the way, it orders our links alphabetically, from January of the starting year\n",
    "                 to December of the end year. '''\n",
    "        partitioned_cities=[self.filtered_cities[i::self.partitions] for i in range(self.partitions)]\n",
    "        partitioned_links=[]\n",
    "        for x in partitioned_cities:\n",
    "            partitioned_links1=[]\n",
    "            for link in self.month_links:\n",
    "                for city in x:\n",
    "                    for year in self.chosen_years:\n",
    "                        if city in link and str(year) in link:\n",
    "                            partitioned_links1.append(link)\n",
    "            partitioned_links1=sorted(partitioned_links1)\n",
    "            month_indeces=[4,3,8,1,7,5,6,0,11,10,9,2]\n",
    "            for r in range(int(len(partitioned_links1)/12)):  # ordering months from January to December\n",
    "                partitioned_links1[(r*12):((r+1)*12)] =[partitioned_links1[(r*12):((r+1)*12)][i] for i in month_indeces]\n",
    "            partitioned_links.append(partitioned_links1)\n",
    "        self.partitioned_links=partitioned_links\n",
    "        return self.partitioned_links\n",
    "    def partitioned_date_city(self):\n",
    "        ''' Making lists of cities, years and months corresponding to the lists of the partitioned links.  '''\n",
    "        partitioned_cities=[]\n",
    "        partitioned_months=[]\n",
    "        partitioned_years=[]\n",
    "        for x in self.partitioned_links:\n",
    "            partitioned_cities.append([y.split(\"/\")[5] for y in x])\n",
    "            partitioned_years.append([y.split(\"/\")[6] for y in x])\n",
    "            partitioned_months.append([y.split(\"/\")[7] for y in x])\n",
    "        self.partitioned_cities=partitioned_cities\n",
    "        self.partitioned_years=partitioned_years\n",
    "        self.partitioned_months=partitioned_months\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' We initialize our link finder with the default options. '''\n",
    "download=ITA_weather_link_finder()\n",
    "\n",
    "''' We run the first method - region_pages - in order to get the links to all region pages and their names. '''\n",
    "reg_pages=download.region_pages()\n",
    "reg_names=download.region_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Next, we get links and names of the cities from the chosen regions. We use all of the available regions that we got \n",
    "      in the previous step. '''\n",
    "city_pages=download.city_pages()\n",
    "cities=download.cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Now we acquire links to pages with the monthly data tables. These data tables are what we are looking for.\n",
    "    However, we are interested only in cities for which there are no missing monthly tables throughout the whole period.\n",
    "    Thus we also acquire lists of available years and corresponding months for each city. '''\n",
    "monthly_pages=download.monthly_pages(cities)\n",
    "avail_years=download.years_per_city   \n",
    "avail_months=download.months_per_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40730"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(monthly_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altogether we have 40,730 available links. We will subset links for the cities which have available data for each month during the 1985-2019 period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: for some reason some of the links lead to a no-data page (links are correct, we get the same result if we move directly on the Italian webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Once we have information about data availability we can filter those cities which we do not want.  '''\n",
    "filtered_cities=download.filtering_cities()\n",
    "years_chosen=download.chosen_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We get 52 cities. For 35 years we would have 21,840 monthly data tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we decide into how many groups we split our links into. For the default value of 2, the download of 1 group takes approximately 2 hours (for my computer). Take this into consideration while trying to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' We now divide the final links into groups as decided by the partitions argument. '''\n",
    "#download.partitions=4\n",
    "parted_links=download.partitioning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10920"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parted_links[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So for 2 partitions we get 10,920 links in both groups to each month in the 1985-2019 period for 26 Italian cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Finally we assign to each link corresponding city, year and month. We will use this during downloading for creation of\n",
    "     data tables. '''\n",
    "download.partitioned_date_city()\n",
    "parted_cities=download.partitioned_cities\n",
    "parted_years= download.partitioned_years\n",
    "parted_months= download.partitioned_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2\n",
    "## Data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An object of class ITA_weather_link_finder will now be used for downloading the monthly tables of daily data from the ilmeteo.it website. This will be performed with the \"downloader\" function. This function uses results of partitioning and  partitioned_date_city method of a ITA_weather_link_finder object. Single use of this function performs downloads for the chosen partition of links provided by the inputed object. \n",
    "\n",
    "## Downloader's inputs are the object, the index number of the links' partition that we want to use, and optional lists of failed links and their indeces. The ouput is a three-item list of:\n",
    "* ## list of lists of dictionaries ready to be turned to panda dataframe tables; in case of a failed download the corresponding item in the output list is [\"error\"]\n",
    "* ## list of links for which download of the table failed\n",
    "* ## list of indeces corresponding to the above mentioned links\n",
    "\n",
    "## Default input for lists of failed links and their indeces are empty lists but they can be also  pre-existing lists to which new items will be added at their ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloader(link_finder,ind, list_of_f_links=[],list_of_f_indeces=[]):    #link_finder is some object of ITA_weather_link_finder class;  \n",
    "    '''     This function utilizes an ITA_weather_link_finder object (particularly results of \"partitioning\"\n",
    "           and \"partitioned_date_city\" methods) to download data-tables using the provided webpage links.\n",
    "        Its output are:\n",
    "           - a list of libraries with variable names and their values, including name of city, year\n",
    "           and month to which they correspond \n",
    "           - a list of links for which download failed\n",
    "           - indeces of the failed links\n",
    "           \n",
    "        When an error is encountered it shows the index of the link for which the download was unsuccessful. Furthermore\n",
    "        it adds the failed link into the list of failed links and its index into the corresponding list of indeces. I adds\n",
    "        a list with item \"error\" inside of it to the list of weather data.\n",
    "           \n",
    "        Each 200 links it also shows the proportion of links already scraped. '''\n",
    "    j=int(ind)\n",
    "    table=[]                       # i is index of the junk of partitioned links we want to download \n",
    "    links=link_finder.partitioned_links[j]\n",
    "    for link in links:\n",
    "        try:\n",
    "            index=int(links.index(link))\n",
    "            month=link_finder.partitioned_months[j][index]    # what month do we scrape with the particular link?\n",
    "            year=str(link_finder.partitioned_years[j][index])      # what year do we scrape?\n",
    "            city=link_finder.partitioned_cities[j][index]       # what city do we scrape?\n",
    "            Dark_values=[]\n",
    "            Light_values=[]\n",
    "            values=[]\n",
    "            page = requests.get(link)             # getting linked webpage\n",
    "            soup1= Bsoup(page.text)\n",
    "            var=soup1.findAll(\"table\")[3].findAll(\"th\")    # find the list of variable names on the webpage\n",
    "            variables=[\"city\",\"year\",\"month\"]                    # making the list of variable names...\n",
    "            [variables.append(x.text) for x in var]     #  ... (for each link separately to check if they are always the same)\n",
    "            temps_dark = soup1.findAll(\"tr\",{'class':'dark'})    # data are in a table with alternating dark \n",
    "            temps_light = soup1.findAll(\"tr\",{'class':'light'})   # and light rows\n",
    "            for x in temps_dark:\n",
    "                tds=x.findAll(\"td\")\n",
    "                dark_value=[city,year,month]\n",
    "                [dark_value.append(y.text) for y in tds]            # getting list of values from each dark row\n",
    "                Dark_values.append(dark_value)\n",
    "            for x in temps_light:\n",
    "                tds=x.findAll(\"td\")\n",
    "                light_value=[city,year,month]\n",
    "                [light_value.append(y.text) for y in tds]          # getting list of values from each light row\n",
    "                Light_values.append(light_value)\n",
    "            if len(temps_dark)==(len(temps_light)+1) or len(temps_dark)==len(temps_light):\n",
    "                for i in range(len(temps_light)):                              \n",
    "                    values.append(Dark_values[i])                   # list of values for months with even number of days\n",
    "                    values.append(Light_values[i])                         \n",
    "            else:\n",
    "                for i in range(len(temps_light)):\n",
    "                    values.append(Dark_values[i])                   # list of values for months with odd number of days\n",
    "                    values.append(Light_values[i])\n",
    "                values.append(Dark_values[len(temps_light)])\n",
    "            tab={variables[i]:[x[i] for x in values] for i in range(len(variables))} # creating a monthly dictionary - variable:list_of_values\n",
    "            table.append(tab)               # in the end, we get a list of monthly dictionaries\n",
    "            if index%200==0:     # checking the progress\n",
    "                progress=index/len(links)\n",
    "                print(str(progress*100)+\"%\")\n",
    "                now = datetime.now()\n",
    "                current_time = now.strftime(\"%H:%M:%S\")\n",
    "                print(current_time)        \n",
    "        except:\n",
    "            table.append([\"error\"])\n",
    "            index=links.index(link)\n",
    "            list_of_f_indeces.append(index)\n",
    "            list_of_f_links.append(link)\n",
    "            print(index)     # if errors, where?\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(current_time)  \n",
    "    return [table,list_of_f_links,list_of_f_indeces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider an example with only subset of 100 links\n",
    "cp=ITA_weather_link_finder(1985,2019)\n",
    "\n",
    "cp.partitioned_links=[x[0:100] for x in download.partitioned_links]\n",
    "\n",
    "cp.partitioned_date_city()\n",
    "\n",
    "len(cp.partitioned_cities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "experiment=downloader(cp,0) # Estimate the time required for the download using timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "19:01:51\n",
      "1.8315018315018317%\n",
      "19:04:12\n",
      "3.6630036630036633%\n",
      "19:06:23\n",
      "5.4945054945054945%\n",
      "19:08:43\n",
      "7.326007326007327%\n",
      "19:11:01\n",
      "9.157509157509157%\n",
      "19:13:11\n",
      "10.989010989010989%\n",
      "19:15:29\n",
      "12.82051282051282%\n",
      "19:17:59\n",
      "14.652014652014653%\n",
      "19:20:40\n",
      "16.483516483516482%\n",
      "19:23:04\n",
      "18.315018315018314%\n",
      "19:25:39\n",
      "20.146520146520146%\n",
      "19:28:00\n",
      "21.978021978021978%\n",
      "19:30:29\n",
      "23.809523809523807%\n",
      "19:32:52\n",
      "25.64102564102564%\n",
      "19:35:14\n",
      "27.472527472527474%\n",
      "19:37:36\n",
      "29.304029304029307%\n",
      "19:39:54\n",
      "31.135531135531135%\n",
      "19:42:10\n",
      "32.967032967032964%\n",
      "19:44:35\n",
      "34.798534798534796%\n",
      "19:47:05\n",
      "36.63003663003663%\n",
      "19:49:37\n",
      "38.46153846153847%\n",
      "19:52:01\n",
      "40.29304029304029%\n",
      "19:54:28\n",
      "42.124542124542124%\n",
      "19:56:52\n",
      "43.956043956043956%\n",
      "19:59:30\n",
      "45.78754578754579%\n",
      "20:02:01\n",
      "47.61904761904761%\n",
      "20:04:26\n",
      "49.45054945054945%\n",
      "20:06:50\n",
      "51.28205128205128%\n",
      "20:09:16\n",
      "53.11355311355312%\n",
      "20:11:44\n",
      "54.94505494505495%\n",
      "20:14:14\n",
      "56.776556776556774%\n",
      "20:16:42\n",
      "58.60805860805861%\n",
      "20:19:32\n",
      "60.43956043956044%\n",
      "20:22:06\n",
      "62.27106227106227%\n",
      "20:24:25\n",
      "64.1025641025641%\n",
      "20:26:48\n",
      "65.93406593406593%\n",
      "20:29:19\n",
      "67.76556776556777%\n",
      "20:31:45\n",
      "69.59706959706959%\n",
      "20:34:04\n",
      "71.42857142857143%\n",
      "20:36:37\n",
      "73.26007326007326%\n",
      "20:38:49\n",
      "75.0915750915751%\n",
      "20:41:19\n",
      "76.92307692307693%\n",
      "20:43:43\n",
      "78.75457875457876%\n",
      "20:45:54\n",
      "80.58608058608058%\n",
      "20:48:06\n",
      "82.41758241758241%\n",
      "20:50:21\n",
      "84.24908424908425%\n",
      "20:52:35\n",
      "86.08058608058609%\n",
      "20:55:00\n",
      "87.91208791208791%\n",
      "20:57:33\n",
      "89.74358974358975%\n",
      "21:00:07\n",
      "91.57509157509158%\n",
      "21:02:38\n",
      "93.4065934065934%\n",
      "21:05:16\n",
      "95.23809523809523%\n",
      "21:08:01\n",
      "97.06959706959707%\n",
      "21:10:42\n",
      "98.9010989010989%\n",
      "21:13:25\n",
      "21:14:58\n"
     ]
    }
   ],
   "source": [
    "''' Download of the first partition. '''\n",
    "down0=downloader(download,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10920\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "''' Assigning tables, failed links and their indeces from the download of the first partition. '''\n",
    "failed_links0=down0[1]\n",
    "failed_indeces0=down0[2]\n",
    "\n",
    "tables0=down0[0]\n",
    "print(len(tables0))\n",
    "print(len(failed_links0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If some tables failed to be downloaded (perhaps dut to faulty internet connection), we can try to get them again. All we need to do is to declare a new ITA_weather_link_finder object with $partitions=1$, assign the list of failed links as its partitioned_links attribute and run partitioned_date_city method. This object can be then used as the input of the downloader function. \n",
    "### Take care that partitioned_links attribute should be a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additions=ITA_weather_link_finder(partitions=1)\n",
    "additions.partitioned_links=[failed_links0]\n",
    "additions.partitioned_date_city()\n",
    "add_down=downloader(additions,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_tables=add_down[0]\n",
    "len(add_down[1])==0  # still some errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can replace [\"error\"] items in our list of tables with the added tables. In case some tables still failed to download, try to repeat the procedure for the \"additions\" object itself. We should be able to download all of the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(failed_indeces0)):\n",
    "               tables0[failed_indeces0[i]]=add_tables[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get all of the tables, we just repeat the same procedure for other partitions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "21:14:59\n",
      "1.8315018315018317%\n",
      "21:18:10\n",
      "3.6630036630036633%\n",
      "21:21:19\n",
      "5.4945054945054945%\n",
      "21:24:34\n",
      "7.326007326007327%\n",
      "21:28:16\n",
      "9.157509157509157%\n",
      "21:32:01\n",
      "10.989010989010989%\n",
      "21:34:42\n",
      "12.82051282051282%\n",
      "21:37:29\n",
      "14.652014652014653%\n",
      "21:39:54\n",
      "16.483516483516482%\n",
      "21:42:46\n",
      "18.315018315018314%\n",
      "21:45:22\n",
      "20.146520146520146%\n",
      "21:47:53\n",
      "21.978021978021978%\n",
      "21:50:17\n",
      "23.809523809523807%\n",
      "21:52:34\n",
      "25.64102564102564%\n",
      "21:54:54\n",
      "27.472527472527474%\n",
      "21:57:11\n",
      "29.304029304029307%\n",
      "21:59:24\n",
      "31.135531135531135%\n",
      "22:01:41\n",
      "32.967032967032964%\n",
      "22:04:01\n",
      "34.798534798534796%\n",
      "22:06:21\n",
      "36.63003663003663%\n",
      "22:08:39\n",
      "38.46153846153847%\n",
      "22:11:03\n",
      "40.29304029304029%\n",
      "22:14:10\n",
      "42.124542124542124%\n",
      "22:16:27\n",
      "43.956043956043956%\n",
      "22:18:43\n",
      "45.78754578754579%\n",
      "22:20:58\n",
      "47.61904761904761%\n",
      "22:23:21\n",
      "49.45054945054945%\n",
      "22:25:43\n",
      "51.28205128205128%\n",
      "22:28:04\n",
      "53.11355311355312%\n",
      "22:30:24\n",
      "54.94505494505495%\n",
      "22:32:41\n",
      "56.776556776556774%\n",
      "22:34:57\n",
      "58.60805860805861%\n",
      "22:37:12\n",
      "60.43956043956044%\n",
      "22:39:37\n",
      "62.27106227106227%\n",
      "22:41:54\n",
      "64.1025641025641%\n",
      "22:44:18\n",
      "65.93406593406593%\n",
      "22:46:37\n",
      "67.76556776556777%\n",
      "22:48:53\n",
      "69.59706959706959%\n",
      "22:51:18\n",
      "71.42857142857143%\n",
      "22:53:39\n",
      "73.26007326007326%\n",
      "22:56:04\n",
      "75.0915750915751%\n",
      "22:58:28\n",
      "76.92307692307693%\n",
      "23:00:53\n",
      "78.75457875457876%\n",
      "23:03:16\n",
      "80.58608058608058%\n",
      "23:05:34\n",
      "82.41758241758241%\n",
      "23:07:48\n",
      "84.24908424908425%\n",
      "23:10:03\n",
      "86.08058608058609%\n",
      "23:12:16\n",
      "87.91208791208791%\n",
      "23:14:28\n",
      "89.74358974358975%\n",
      "23:16:45\n",
      "91.57509157509158%\n",
      "23:19:07\n",
      "93.4065934065934%\n",
      "23:21:27\n",
      "95.23809523809523%\n",
      "23:23:43\n",
      "97.06959706959707%\n",
      "23:26:02\n",
      "98.9010989010989%\n",
      "23:28:18\n",
      "23:29:38\n"
     ]
    }
   ],
   "source": [
    "down1=downloader(download,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10920\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "''' Assigning tables, failed links and their indeces from the download of the second partition. '''\n",
    "failed_links1=down1[1]\n",
    "failed_indeces1=down1[2]\n",
    "\n",
    "tables1=down1[0]\n",
    "print(len(tables1))\n",
    "print(len(failed_links1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can now check whether are the names and order of the variables inside of each table the same, ie. if all tables have the same structure. We then transform the tables inside proper panda dataframes and export them as csv files for the use in next parts of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''  Are the name of the variables always the same (including their order)?    '''\n",
    "print(sum([list(x.keys())==list(tables0[0].keys()) for x in tables0])==len(tables0))\n",
    "print(sum([list(x.keys())==list(tables1[0].keys()) for x in tables1])==len(tables1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''    Creating list of dataframes - each month of each city is a single dataframe  '''\n",
    "list_of_DF0=[pd.DataFrame(x) for x in tables0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''    Creating list of dataframes  '''\n",
    "list_of_DF1=[pd.DataFrame(x) for x in tables1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''     Exporting dataframes to the csv files        '''\n",
    "df_paths0=['d:\\moje_dokumenty\\Desktop\\IES\\semester 11\\Python\\project\\DATA1\\ '+str(10000+tables0.index(x))+\".csv\" for x in tables0]\n",
    "[list_of_DF0[df_paths0.index(x)].to_csv(x, index = None, header=True) for x in df_paths0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''     Exporting dataframes to the csv files        '''\n",
    "df_paths1=['d:\\moje_dokumenty\\Desktop\\IES\\semester 11\\Python\\project\\DATA02\\ '+str(10000+tables1.index(x))+\".csv\" for x in tables1]\n",
    "[list_of_DF1[df_paths1.index(x)].to_csv(x, index = None, header=True) for x in df_paths1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
